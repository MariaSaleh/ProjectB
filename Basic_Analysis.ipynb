{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-03-27', '2020-02-14', '2020-02-15', '2020-03-26']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DatesDic2List(dates_dictionary):\n",
    "    '''\n",
    "    DatesDic2List takes a dictionary with the following format:\n",
    "    { 'date_as_string': number of days as integer,...}\n",
    "    returns a list with the range of dates of each item in the dictionary + the num of days \n",
    "    '''\n",
    "    dates_list = []\n",
    "    for date, date_range in dates_dictionary.items():\n",
    "        dates_list.append(date)\n",
    "        i = 1 \n",
    "        sign = lambda a: (a>0) - (a<0)\n",
    "        while(abs(date_range)>0):\n",
    "            new_date = pd.to_datetime(date) + (sign(date_range) * timedelta(days=i))\n",
    "            dates_list.append(new_date.strftime(\"%Y-%m-%d\"))\n",
    "            i = i+1\n",
    "            date_range = date_range-(1*(sign (date_range)))\n",
    "           \n",
    "                    \n",
    "    return list(set(dates_list))\n",
    "\n",
    "\n",
    "\n",
    "date_list = DatesDic2List({'2020-03-27':-1,'2020-02-14':1})\n",
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sample_data.xlsx'\n",
    "file_path2 = 'latest/all_daily.csv'\n",
    "date_range_dict = {'2020-01-22':3}\n",
    "#date_range_dict = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitLogger(file_path):\n",
    "    # logger initiation\n",
    "    \n",
    "    # create logger \n",
    "    logger = logging.getLogger('sample')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.propagate = False\n",
    "    \n",
    "    # create file handler\n",
    "    fh = logging.FileHandler(file_path,mode='w')\n",
    "    fh.setLevel(logging.INFO)\n",
    "    \n",
    "    # create formatter and add it to the handlers\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)    \n",
    "    logger.addHandler(fh)\n",
    "    \n",
    "    return(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadFile(file_path, _attr_date = 'date_ymd'):\n",
    "    # Read File according to file extension\n",
    "    if file_path.endswith(\".xlsx\"):\n",
    "        xlsx = pd.ExcelFile(file_path)\n",
    "        df = pd.read_excel(xlsx)\n",
    "    elif file_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_path, parse_dates=[_attr_date])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractRegionProvince(r_p_dic, df, _attr_region = 'Country_Region', _attr_province = 'Province_State'):\n",
    "    # Region and Province Selection\n",
    "    # r_p_dic = region_province_dictionary\n",
    "    \n",
    "    df_extract = df\n",
    "    mask_prev =  [False]*len(df.index)\n",
    "    if r_p_dic != {}:\n",
    "        for region, provinces in r_p_dic.items():\n",
    "            \n",
    "            if (provinces == []) or (provinces == None) :\n",
    "                mask = mask_prev | (df_extract[_attr_region] == region ) \n",
    "                mask_prev = mask\n",
    "                continue\n",
    "            for province in provinces:\n",
    "                mask = mask_prev | ((df_extract[_attr_region] == region ) & (df_extract[_attr_province] == province)) \n",
    "                mask_prev = mask\n",
    "        df_extract = df.loc[mask]\n",
    "    else:\n",
    "        df_extract = df\n",
    "    return(df_extract)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def DataParser(file_path, date_range_dict, incubation_duration = 5, r_p_dic = {}, \\\n",
    "               attr_extract = None, _attr_date = 'date_ymd', _attr_region = 'Country_Region', \\\n",
    "               _attr_province = 'Province_State'):\n",
    "    \n",
    "    # init logger and log run parameters\n",
    "    logger = InitLogger('dataparsing.log')\n",
    "    logger.info('Incubation date: {}'.format(incubation_duration))\n",
    "    \n",
    "    # read data\n",
    "    df = ReadFile(file_path, _attr_date)\n",
    "    \n",
    "    # extract regions and provinces from df\n",
    "    df_extract = ExtractRegionProvince(r_p_dic, df, _attr_region, _attr_province)\n",
    "\n",
    "    # DateParsing - create a mask to choose the desired dates (According to list and incubation period)\n",
    "    df_final = pd.DataFrame() # creates a new dataframe that's empty\n",
    "    if date_range_dict != None:\n",
    "        date_list = DatesDic2List(date_range_dict)\n",
    "        for date in date_list:\n",
    "            # get the incubation period of the date\n",
    "            curr_date_df = df_extract.loc[:,_attr_date: _attr_region]\n",
    "            end_date = (pd.to_datetime(date)-timedelta(days=incubation_duration)) \n",
    "            mask = (df_extract[_attr_date] >= end_date) & (df_extract[_attr_date] <= date)\n",
    "            incubation_df_extract = df_extract.loc[mask] # extracts the incubation period of the date\n",
    "            att_df_final = incubation_df_extract.groupby([_attr_region],as_index=False).agg(attr_extract)\n",
    "            att_df_final.insert(0,_attr_date,date,True)\n",
    "            att_df_final.columns = att_df_final.columns.map('_'.join)\n",
    "            # TO DO: join will add \"_\" to the end of columns titles that consist of one line, which is undesired\n",
    "            #        make sure titles are back to normal\n",
    "            mask_date =  [False]*len(df_extract.index)\n",
    "            mask_date = mask_date | (df_extract[_attr_date] == date)\n",
    "            for attr in attr_extract:\n",
    "                df_date = df_extract.loc[mask_date]\n",
    "                df_attr = df_date[[attr]]\n",
    "                if len(df_attr.values.tolist())!=0:\n",
    "                    att_df_final[attr] = pd.Series(df_attr.values.tolist()).str.get(0)\n",
    "            if not att_df_final.empty:\n",
    "                df_final = df_final.append(att_df_final, ignore_index = False) # ignoring index is optional\n",
    "                df_final = df_final.sort_values(by=_attr_date+'_')\n",
    "    else:\n",
    "        df_final = df_extract.groupby(by=[_attr_region],as_index=False).agg(attr_extract) \n",
    "        df_final.insert(0,_attr_date,'ALL',True)\n",
    "    \n",
    "    df_final.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2:\n",
      "         date_ Country_Region_  Confirmed_mean  Confirmed\n",
      "0   2020-03-03       Argentina        1.000000        1.0\n",
      "1   2020-03-04       Argentina        1.000000        1.0\n",
      "2   2020-03-05       Argentina        1.000000        1.0\n",
      "3   2020-03-06       Argentina        1.250000        2.0\n",
      "4   2020-03-07       Argentina        2.600000        8.0\n",
      "5   2020-03-08       Argentina        4.166667       12.0\n",
      "6   2020-03-09       Argentina        6.000000       12.0\n",
      "7   2020-03-10       Argentina        8.666667       17.0\n",
      "8   2020-03-11       Argentina       11.666667       19.0\n",
      "9   2020-03-12       Argentina       14.500000       19.0\n",
      "10  2020-03-13       Argentina       18.333333       31.0\n",
      "11  2020-03-14       Argentina       22.000000       34.0\n",
      "12  2020-03-15       Argentina       27.500000       45.0\n",
      "13  2020-03-16       Argentina       34.000000       56.0\n",
      "14  2020-03-17       Argentina       42.166667       68.0\n",
      "15  2020-03-18       Argentina       52.166667       79.0\n",
      "16  2020-03-19       Argentina       63.166667       97.0\n",
      "17  2020-03-20       Argentina       78.833333      128.0\n",
      "18  2020-03-21       Argentina       97.666667      158.0\n",
      "19  2020-03-22       Argentina      132.666667      266.0\n",
      "20  2020-03-23       Argentina      165.666667      266.0\n",
      "21  2020-03-24       Argentina      217.000000      387.0\n",
      "22  2020-03-25       Argentina      265.333333      387.0\n",
      "23  2020-03-26       Argentina      327.666667      502.0\n",
      "24  2020-03-27       Argentina      399.500000      589.0\n",
      "25  2020-03-28       Argentina      470.166667      690.0\n",
      "26  2020-03-29       Argentina      550.000000      745.0\n",
      "27  2020-03-30       Argentina      622.166667      820.0\n",
      "28  2020-03-31       Argentina      733.333333     1054.0\n",
      "29  2020-04-01       Argentina      825.333333     1054.0\n",
      "30  2020-04-02       Argentina      916.000000     1133.0\n",
      "31  2020-04-03       Argentina     1011.833333     1265.0\n",
      "32  2020-04-04       Argentina     1129.500000     1451.0\n",
      "33  2020-04-05       Argentina     1234.666667     1451.0\n",
      "34  2020-04-06       Argentina     1318.000000     1554.0\n",
      "35  2020-04-07       Argentina     1413.666667     1628.0\n",
      "36  2020-04-08       Argentina     1510.666667     1715.0\n",
      "37  2020-04-09       Argentina     1599.000000     1795.0\n",
      "38  2020-04-10       Argentina     1686.333333     1975.0\n",
      "39  2020-04-11       Argentina     1773.666667     1975.0\n"
     ]
    }
   ],
   "source": [
    "#df1 = DataParser(file_path2, None, _attr_date = 'date',r_p_dic={'Argentina':[],'Israel':[],'Mainland China':['Shaanxi']}, attr_extract={'Confirmed':['max','min']})\n",
    "\n",
    "\n",
    "#date_range_dict = {'2020-01-22':80}\n",
    "#df2 = DataParser(file_path2, date_range_dict, _attr_date = 'date',r_p_dic={'Argentina':[],'Israel':[],'Sweden':[],'Mainland China':['Shaanxi']}, attr_extract={'Confirmed':['mean']})\n",
    "#df1\n",
    "#df2\n",
    "\n",
    "date_range_dict = {'2020-01-22':80}\n",
    "df2 = DataParser(file_path2, date_range_dict, _attr_date = 'date',r_p_dic={'Argentina':[]}, attr_extract={'Confirmed':['mean']})\n",
    "print(\"df2:\")\n",
    "print(df2)\n",
    "\n",
    "# attr_extract={'confirmed_cases':['mean','min'],'mean_temp': ['max']} ,region=['Mainland China'], province = ['Anhui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
